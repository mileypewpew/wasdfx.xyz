// src/index.ts
import { createOpenAI } from "@ai-sdk/openai";
import { EventType, logger, ModelType, VECTOR_DIMS } from "@elizaos/core";
import {
  generateObject,
  generateText,
  JSONParseError
} from "ai";
import { encodingForModel } from "js-tiktoken";
function getSetting(runtime, key, defaultValue) {
  return runtime.getSetting(key) ?? process.env[key] ?? defaultValue;
}
function isBrowser() {
  return typeof globalThis !== "undefined" && typeof globalThis.document !== "undefined";
}
function isProxyMode(runtime) {
  return isBrowser() && !!getSetting(runtime, "OPENAI_BROWSER_BASE_URL");
}
function getAuthHeader(runtime, forEmbedding = false) {
  if (isBrowser())
    return {};
  const key = forEmbedding ? getEmbeddingApiKey(runtime) : getApiKey(runtime);
  return key ? { Authorization: `Bearer ${key}` } : {};
}
function getBaseURL(runtime) {
  const browserURL = getSetting(runtime, "OPENAI_BROWSER_BASE_URL");
  const baseURL = isBrowser() && browserURL ? browserURL : getSetting(runtime, "OPENAI_BASE_URL", "https://api.openai.com/v1");
  logger.debug(`[OpenAI] Default base URL: ${baseURL}`);
  return baseURL;
}
function getEmbeddingBaseURL(runtime) {
  const embeddingURL = isBrowser() ? getSetting(runtime, "OPENAI_BROWSER_EMBEDDING_URL") || getSetting(runtime, "OPENAI_BROWSER_BASE_URL") : getSetting(runtime, "OPENAI_EMBEDDING_URL");
  if (embeddingURL) {
    logger.debug(`[OpenAI] Using specific embedding base URL: ${embeddingURL}`);
    return embeddingURL;
  }
  logger.debug("[OpenAI] Falling back to general base URL for embeddings.");
  return getBaseURL(runtime);
}
function getApiKey(runtime) {
  return getSetting(runtime, "OPENAI_API_KEY");
}
function getEmbeddingApiKey(runtime) {
  const embeddingApiKey = getSetting(runtime, "OPENAI_EMBEDDING_API_KEY");
  if (embeddingApiKey) {
    logger.debug("[OpenAI] Using specific embedding API key (present)");
    return embeddingApiKey;
  }
  logger.debug("[OpenAI] Falling back to general API key for embeddings.");
  return getApiKey(runtime);
}
function getSmallModel(runtime) {
  return getSetting(runtime, "OPENAI_SMALL_MODEL") ?? getSetting(runtime, "SMALL_MODEL", "gpt-5-nano");
}
function getLargeModel(runtime) {
  return getSetting(runtime, "OPENAI_LARGE_MODEL") ?? getSetting(runtime, "LARGE_MODEL", "gpt-5-mini");
}
function getImageDescriptionModel(runtime) {
  return getSetting(runtime, "OPENAI_IMAGE_DESCRIPTION_MODEL", "gpt-5-nano") ?? "gpt-5-nano";
}
function getExperimentalTelemetry(runtime) {
  const setting = getSetting(runtime, "OPENAI_EXPERIMENTAL_TELEMETRY", "false");
  const normalizedSetting = String(setting).toLowerCase();
  const result = normalizedSetting === "true";
  logger.debug(`[OpenAI] Experimental telemetry in function: "${setting}" (type: ${typeof setting}, normalized: "${normalizedSetting}", result: ${result})`);
  return result;
}
function createOpenAIClient(runtime) {
  const baseURL = getBaseURL(runtime);
  const apiKey = getApiKey(runtime) ?? (isProxyMode(runtime) ? "sk-proxy" : undefined);
  return createOpenAI({ apiKey: apiKey ?? "", baseURL });
}
async function tokenizeText(model, prompt) {
  const modelName = model === ModelType.TEXT_SMALL ? process.env.OPENAI_SMALL_MODEL ?? process.env.SMALL_MODEL ?? "gpt-5-nano" : process.env.LARGE_MODEL ?? "gpt-5-mini";
  const tokens = encodingForModel(modelName).encode(prompt);
  return tokens;
}
async function detokenizeText(model, tokens) {
  const modelName = model === ModelType.TEXT_SMALL ? process.env.OPENAI_SMALL_MODEL ?? process.env.SMALL_MODEL ?? "gpt-5-nano" : process.env.OPENAI_LARGE_MODEL ?? process.env.LARGE_MODEL ?? "gpt-5-mini";
  return encodingForModel(modelName).decode(tokens);
}
async function generateObjectByModelType(runtime, params, modelType, getModelFn) {
  const openai = createOpenAIClient(runtime);
  const modelName = getModelFn(runtime);
  logger.log(`[OpenAI] Using ${modelType} model: ${modelName}`);
  const temperature = params.temperature ?? 0;
  const schemaPresent = !!params.schema;
  if (schemaPresent) {
    logger.info(`Using ${modelType} without schema validation (schema provided but output=no-schema)`);
  }
  try {
    const { object, usage } = await generateObject({
      model: openai.languageModel(modelName),
      output: "no-schema",
      prompt: params.prompt,
      temperature,
      experimental_repairText: getJsonRepairFunction()
    });
    if (usage) {
      emitModelUsageEvent(runtime, modelType, params.prompt, usage);
    }
    return object;
  } catch (error) {
    if (error instanceof JSONParseError) {
      logger.error(`[generateObject] Failed to parse JSON: ${error.message}`);
      const repairFunction = getJsonRepairFunction();
      const repairedJsonString = await repairFunction({
        text: error.text,
        error
      });
      if (repairedJsonString) {
        try {
          const repairedObject = JSON.parse(repairedJsonString);
          logger.info("[generateObject] Successfully repaired JSON.");
          return repairedObject;
        } catch (repairParseError) {
          const message = repairParseError instanceof Error ? repairParseError.message : String(repairParseError);
          logger.error(`[generateObject] Failed to parse repaired JSON: ${message}`);
          throw repairParseError;
        }
      } else {
        logger.error("[generateObject] JSON repair failed.");
        throw error;
      }
    } else {
      const message = error instanceof Error ? error.message : String(error);
      logger.error(`[generateObject] Unknown error: ${message}`);
      throw error;
    }
  }
}
function getJsonRepairFunction() {
  return async ({ text, error }) => {
    try {
      if (error instanceof JSONParseError) {
        const cleanedText = text.replace(/```json\n|\n```|```/g, "");
        JSON.parse(cleanedText);
        return cleanedText;
      }
      return null;
    } catch (jsonError) {
      const message = jsonError instanceof Error ? jsonError.message : String(jsonError);
      logger.warn(`Failed to repair JSON text: ${message}`);
      return null;
    }
  };
}
function emitModelUsageEvent(runtime, type, prompt, usage) {
  runtime.emitEvent(EventType.MODEL_USED, {
    provider: "openai",
    type,
    prompt,
    tokens: {
      prompt: usage.inputTokens,
      completion: usage.outputTokens,
      total: usage.totalTokens
    }
  });
}
async function fetchTextToSpeech(runtime, options) {
  const defaultModel = getSetting(runtime, "OPENAI_TTS_MODEL", "gpt-4o-mini-tts");
  const defaultVoice = getSetting(runtime, "OPENAI_TTS_VOICE", "nova");
  const defaultInstructions = getSetting(runtime, "OPENAI_TTS_INSTRUCTIONS", "");
  const baseURL = getBaseURL(runtime);
  const model = options.model || defaultModel;
  const voice = options.voice || defaultVoice;
  const instructions = options.instructions ?? defaultInstructions;
  const format = options.format || "mp3";
  try {
    const res = await fetch(`${baseURL}/audio/speech`, {
      method: "POST",
      headers: {
        ...getAuthHeader(runtime),
        "Content-Type": "application/json",
        ...format === "mp3" ? { Accept: "audio/mpeg" } : {}
      },
      body: JSON.stringify({
        model,
        voice,
        input: options.text,
        format,
        ...instructions && { instructions }
      })
    });
    if (!res.ok) {
      const err = await res.text();
      throw new Error(`OpenAI TTS error ${res.status}: ${err}`);
    }
    return res.body;
  } catch (err) {
    const message = err instanceof Error ? err.message : String(err);
    throw new Error(`Failed to fetch speech from OpenAI TTS: ${message}`);
  }
}
var openaiPlugin = {
  name: "openai",
  description: "OpenAI plugin",
  config: {
    OPENAI_API_KEY: process.env.OPENAI_API_KEY,
    OPENAI_BASE_URL: process.env.OPENAI_BASE_URL,
    OPENAI_SMALL_MODEL: process.env.OPENAI_SMALL_MODEL,
    OPENAI_LARGE_MODEL: process.env.OPENAI_LARGE_MODEL,
    SMALL_MODEL: process.env.SMALL_MODEL,
    LARGE_MODEL: process.env.LARGE_MODEL,
    OPENAI_EMBEDDING_MODEL: process.env.OPENAI_EMBEDDING_MODEL,
    OPENAI_EMBEDDING_API_KEY: process.env.OPENAI_EMBEDDING_API_KEY,
    OPENAI_EMBEDDING_URL: process.env.OPENAI_EMBEDDING_URL,
    OPENAI_EMBEDDING_DIMENSIONS: process.env.OPENAI_EMBEDDING_DIMENSIONS,
    OPENAI_IMAGE_DESCRIPTION_MODEL: process.env.OPENAI_IMAGE_DESCRIPTION_MODEL,
    OPENAI_IMAGE_DESCRIPTION_MAX_TOKENS: process.env.OPENAI_IMAGE_DESCRIPTION_MAX_TOKENS,
    OPENAI_EXPERIMENTAL_TELEMETRY: process.env.OPENAI_EXPERIMENTAL_TELEMETRY
  },
  async init(_config, runtime) {
    new Promise(async (resolve) => {
      resolve();
      try {
        if (!getApiKey(runtime) && !isBrowser()) {
          logger.warn("OPENAI_API_KEY is not set in environment - OpenAI functionality will be limited");
          return;
        }
        try {
          const baseURL = getBaseURL(runtime);
          const response = await fetch(`${baseURL}/models`, {
            headers: { ...getAuthHeader(runtime) }
          });
          if (!response.ok) {
            logger.warn(`OpenAI API key validation failed: ${response.statusText}`);
            logger.warn("OpenAI functionality will be limited until a valid API key is provided");
          } else {
            logger.log("OpenAI API key validated successfully");
          }
        } catch (fetchError) {
          const message = fetchError instanceof Error ? fetchError.message : String(fetchError);
          logger.warn(`Error validating OpenAI API key: ${message}`);
          logger.warn("OpenAI functionality will be limited until a valid API key is provided");
        }
      } catch (error) {
        const message = error?.errors?.map((e) => e.message).join(", ") || (error instanceof Error ? error.message : String(error));
        logger.warn(`OpenAI plugin configuration issue: ${message} - You need to configure the OPENAI_API_KEY in your environment variables`);
      }
    });
  },
  models: {
    [ModelType.TEXT_EMBEDDING]: async (runtime, params) => {
      const embeddingModelName = getSetting(runtime, "OPENAI_EMBEDDING_MODEL", "text-embedding-3-small");
      const embeddingDimension = Number.parseInt(getSetting(runtime, "OPENAI_EMBEDDING_DIMENSIONS", "1536") || "1536", 10);
      if (!Object.values(VECTOR_DIMS).includes(embeddingDimension)) {
        const errorMsg = `Invalid embedding dimension: ${embeddingDimension}. Must be one of: ${Object.values(VECTOR_DIMS).join(", ")}`;
        logger.error(errorMsg);
        throw new Error(errorMsg);
      }
      if (params === null) {
        logger.debug("Creating test embedding for initialization");
        const testVector = Array(embeddingDimension).fill(0);
        testVector[0] = 0.1;
        return testVector;
      }
      let text;
      if (typeof params === "string") {
        text = params;
      } else if (typeof params === "object" && params.text) {
        text = params.text;
      } else {
        logger.warn("Invalid input format for embedding");
        const fallbackVector = Array(embeddingDimension).fill(0);
        fallbackVector[0] = 0.2;
        return fallbackVector;
      }
      if (!text.trim()) {
        logger.warn("Empty text for embedding");
        const emptyVector = Array(embeddingDimension).fill(0);
        emptyVector[0] = 0.3;
        return emptyVector;
      }
      const embeddingBaseURL = getEmbeddingBaseURL(runtime);
      try {
        const response = await fetch(`${embeddingBaseURL}/embeddings`, {
          method: "POST",
          headers: {
            ...getAuthHeader(runtime, true),
            "Content-Type": "application/json"
          },
          body: JSON.stringify({
            model: embeddingModelName,
            input: text
          })
        });
        if (!response.ok) {
          logger.error(`OpenAI API error: ${response.status} - ${response.statusText}`);
          const errorVector = Array(embeddingDimension).fill(0);
          errorVector[0] = 0.4;
          return errorVector;
        }
        const data = await response.json();
        if (!data?.data?.[0]?.embedding) {
          logger.error("API returned invalid structure");
          const errorVector = Array(embeddingDimension).fill(0);
          errorVector[0] = 0.5;
          return errorVector;
        }
        const embedding = data.data[0].embedding;
        if (data.usage) {
          const usage = {
            inputTokens: data.usage.prompt_tokens,
            outputTokens: 0,
            totalTokens: data.usage.total_tokens
          };
          emitModelUsageEvent(runtime, ModelType.TEXT_EMBEDDING, text, usage);
        }
        logger.log(`Got valid embedding with length ${embedding.length}`);
        return embedding;
      } catch (error) {
        const message = error instanceof Error ? error.message : String(error);
        logger.error(`Error generating embedding: ${message}`);
        const errorVector = Array(embeddingDimension).fill(0);
        errorVector[0] = 0.6;
        return errorVector;
      }
    },
    [ModelType.TEXT_TOKENIZER_ENCODE]: async (_runtime, { prompt, modelType = ModelType.TEXT_LARGE }) => {
      return await tokenizeText(modelType ?? ModelType.TEXT_LARGE, prompt);
    },
    [ModelType.TEXT_TOKENIZER_DECODE]: async (_runtime, { tokens, modelType = ModelType.TEXT_LARGE }) => {
      return await detokenizeText(modelType ?? ModelType.TEXT_LARGE, tokens);
    },
    [ModelType.TEXT_SMALL]: async (runtime, {
      prompt,
      stopSequences = [],
      maxTokens = 8192,
      temperature = 0.7,
      frequencyPenalty = 0.7,
      presencePenalty = 0.7
    }) => {
      const openai = createOpenAIClient(runtime);
      const modelName = getSmallModel(runtime);
      const experimentalTelemetry = getExperimentalTelemetry(runtime);
      logger.log(`[OpenAI] Using TEXT_SMALL model: ${modelName}`);
      logger.log(prompt);
      const { text: openaiResponse, usage } = await generateText({
        model: openai.languageModel(modelName),
        prompt,
        system: runtime.character.system ?? undefined,
        temperature,
        maxOutputTokens: maxTokens,
        frequencyPenalty,
        presencePenalty,
        stopSequences,
        experimental_telemetry: {
          isEnabled: experimentalTelemetry
        }
      });
      if (usage) {
        emitModelUsageEvent(runtime, ModelType.TEXT_SMALL, prompt, usage);
      }
      return openaiResponse;
    },
    [ModelType.TEXT_LARGE]: async (runtime, {
      prompt,
      stopSequences = [],
      maxTokens = 8192,
      temperature = 0.7,
      frequencyPenalty = 0.7,
      presencePenalty = 0.7
    }) => {
      const openai = createOpenAIClient(runtime);
      const modelName = getLargeModel(runtime);
      const experimentalTelemetry = getExperimentalTelemetry(runtime);
      logger.log(`[OpenAI] Using TEXT_LARGE model: ${modelName}`);
      logger.log(prompt);
      const { text: openaiResponse, usage } = await generateText({
        model: openai.languageModel(modelName),
        prompt,
        system: runtime.character.system ?? undefined,
        temperature,
        maxOutputTokens: maxTokens,
        frequencyPenalty,
        presencePenalty,
        stopSequences,
        experimental_telemetry: {
          isEnabled: experimentalTelemetry
        }
      });
      if (usage) {
        emitModelUsageEvent(runtime, ModelType.TEXT_LARGE, prompt, usage);
      }
      return openaiResponse;
    },
    [ModelType.IMAGE]: async (runtime, params) => {
      const n = params.n || 1;
      const size = params.size || "1024x1024";
      const prompt = params.prompt;
      const modelName = "gpt-image-1";
      logger.log(`[OpenAI] Using IMAGE model: ${modelName}`);
      const baseURL = getBaseURL(runtime);
      try {
        const response = await fetch(`${baseURL}/images/generations`, {
          method: "POST",
          headers: {
            ...getAuthHeader(runtime),
            "Content-Type": "application/json"
          },
          body: JSON.stringify({
            model: modelName,
            prompt,
            n,
            size
          })
        });
        if (!response.ok) {
          throw new Error(`Failed to generate image: ${response.statusText}`);
        }
        const data = await response.json();
        const typedData = data;
        return typedData.data;
      } catch (error) {
        const message = error instanceof Error ? error.message : String(error);
        throw error;
      }
    },
    [ModelType.IMAGE_DESCRIPTION]: async (runtime, params) => {
      let imageUrl;
      let promptText;
      const modelName = getImageDescriptionModel(runtime);
      logger.log(`[OpenAI] Using IMAGE_DESCRIPTION model: ${modelName}`);
      const maxTokens = Number.parseInt(getSetting(runtime, "OPENAI_IMAGE_DESCRIPTION_MAX_TOKENS", "8192") || "8192", 10);
      if (typeof params === "string") {
        imageUrl = params;
        promptText = "Please analyze this image and provide a title and detailed description.";
      } else {
        imageUrl = params.imageUrl;
        promptText = params.prompt || "Please analyze this image and provide a title and detailed description.";
      }
      const messages = [
        {
          role: "user",
          content: [
            { type: "text", text: promptText },
            { type: "image_url", image_url: { url: imageUrl } }
          ]
        }
      ];
      const baseURL = getBaseURL(runtime);
      try {
        const requestBody = {
          model: modelName,
          messages,
          max_tokens: maxTokens
        };
        const response = await fetch(`${baseURL}/chat/completions`, {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            ...getAuthHeader(runtime)
          },
          body: JSON.stringify(requestBody)
        });
        if (!response.ok) {
          throw new Error(`OpenAI API error: ${response.status}`);
        }
        const result = await response.json();
        const typedResult = result;
        const content = typedResult.choices?.[0]?.message?.content;
        if (typedResult.usage) {
          emitModelUsageEvent(runtime, ModelType.IMAGE_DESCRIPTION, typeof params === "string" ? params : params.prompt || "", {
            inputTokens: typedResult.usage.prompt_tokens,
            outputTokens: typedResult.usage.completion_tokens,
            totalTokens: typedResult.usage.total_tokens
          });
        }
        if (!content) {
          return {
            title: "Failed to analyze image",
            description: "No response from API"
          };
        }
        const isCustomPrompt = typeof params === "object" && params.prompt && params.prompt !== "Please analyze this image and provide a title and detailed description.";
        if (isCustomPrompt) {
          return content;
        }
        const titleMatch = content.match(/title[:\s]+(.+?)(?:\n|$)/i);
        const title = titleMatch?.[1]?.trim() || "Image Analysis";
        const description = content.replace(/title[:\s]+(.+?)(?:\n|$)/i, "").trim();
        const processedResult = { title, description };
        return processedResult;
      } catch (error) {
        const message = error instanceof Error ? error.message : String(error);
        logger.error(`Error analyzing image: ${message}`);
        return {
          title: "Failed to analyze image",
          description: `Error: ${message}`
        };
      }
    },
    [ModelType.TRANSCRIPTION]: async (runtime, input) => {
      let modelName = getSetting(runtime, "OPENAI_TRANSCRIPTION_MODEL", "gpt-4o-mini-transcribe");
      logger.log(`[OpenAI] Using TRANSCRIPTION model: ${modelName}`);
      const baseURL = getBaseURL(runtime);
      let blob;
      let extraParams = null;
      if (input instanceof Blob || input instanceof File) {
        blob = input;
      } else if (typeof input === "object" && input !== null && input.audio != null) {
        const params = input;
        if (!(params.audio instanceof Blob) && !(params.audio instanceof File)) {
          throw new Error("TRANSCRIPTION param 'audio' must be a Blob/File. Wrap buffers as: new Blob([buffer], { type: 'audio/mpeg' })");
        }
        blob = params.audio;
        extraParams = params;
        if (typeof params.model === "string" && params.model) {
          modelName = params.model;
        }
      } else {
        throw new Error("TRANSCRIPTION expects a Blob/File or an object { audio: Blob/File, language?, response_format?, timestampGranularities?, prompt?, temperature?, model? }");
      }
      const mime = blob.type || "audio/webm";
      const filename = blob.name || (mime.includes("mp3") || mime.includes("mpeg") ? "recording.mp3" : mime.includes("ogg") ? "recording.ogg" : mime.includes("wav") ? "recording.wav" : mime.includes("webm") ? "recording.webm" : "recording.bin");
      const formData = new FormData;
      formData.append("file", blob, filename);
      formData.append("model", String(modelName));
      if (extraParams) {
        if (typeof extraParams.language === "string") {
          formData.append("language", String(extraParams.language));
        }
        if (typeof extraParams.response_format === "string") {
          formData.append("response_format", String(extraParams.response_format));
        }
        if (typeof extraParams.prompt === "string") {
          formData.append("prompt", String(extraParams.prompt));
        }
        if (typeof extraParams.temperature === "number") {
          formData.append("temperature", String(extraParams.temperature));
        }
        if (Array.isArray(extraParams.timestampGranularities)) {
          for (const g of extraParams.timestampGranularities) {
            formData.append("timestamp_granularities[]", String(g));
          }
        }
      }
      try {
        const response = await fetch(`${baseURL}/audio/transcriptions`, {
          method: "POST",
          headers: {
            ...getAuthHeader(runtime)
          },
          body: formData
        });
        if (!response.ok) {
          throw new Error(`Failed to transcribe audio: ${response.status} ${response.statusText}`);
        }
        const data = await response.json();
        return data.text || "";
      } catch (error) {
        const message = error instanceof Error ? error.message : String(error);
        logger.error(`TRANSCRIPTION error: ${message}`);
        throw error;
      }
    },
    [ModelType.TEXT_TO_SPEECH]: async (runtime, input) => {
      const options = typeof input === "string" ? { text: input } : input;
      const resolvedModel = options.model || getSetting(runtime, "OPENAI_TTS_MODEL", "gpt-4o-mini-tts");
      logger.log(`[OpenAI] Using TEXT_TO_SPEECH model: ${resolvedModel}`);
      try {
        const speechStream = await fetchTextToSpeech(runtime, options);
        return speechStream;
      } catch (error) {
        const message = error instanceof Error ? error.message : String(error);
        logger.error(`Error in TEXT_TO_SPEECH: ${message}`);
        throw error;
      }
    },
    [ModelType.OBJECT_SMALL]: async (runtime, params) => {
      return generateObjectByModelType(runtime, params, ModelType.OBJECT_SMALL, getSmallModel);
    },
    [ModelType.OBJECT_LARGE]: async (runtime, params) => {
      return generateObjectByModelType(runtime, params, ModelType.OBJECT_LARGE, getLargeModel);
    }
  },
  tests: [
    {
      name: "openai_plugin_tests",
      tests: [
        {
          name: "openai_test_url_and_api_key_validation",
          fn: async (runtime) => {
            const baseURL = getBaseURL(runtime);
            const response = await fetch(`${baseURL}/models`, {
              headers: {
                Authorization: `Bearer ${getApiKey(runtime)}`
              }
            });
            const data = await response.json();
            logger.log({ data: data?.data?.length ?? "N/A" }, "Models Available");
            if (!response.ok) {
              throw new Error(`Failed to validate OpenAI API key: ${response.statusText}`);
            }
          }
        },
        {
          name: "openai_test_text_embedding",
          fn: async (runtime) => {
            try {
              const embedding = await runtime.useModel(ModelType.TEXT_EMBEDDING, {
                text: "Hello, world!"
              });
              logger.log({ embedding }, "embedding");
            } catch (error) {
              const message = error instanceof Error ? error.message : String(error);
              logger.error(`Error in test_text_embedding: ${message}`);
              throw error;
            }
          }
        },
        {
          name: "openai_test_text_large",
          fn: async (runtime) => {
            try {
              const text = await runtime.useModel(ModelType.TEXT_LARGE, {
                prompt: "What is the nature of reality in 10 words?"
              });
              if (text.length === 0) {
                throw new Error("Failed to generate text");
              }
              logger.log({ text }, "generated with test_text_large");
            } catch (error) {
              const message = error instanceof Error ? error.message : String(error);
              logger.error(`Error in test_text_large: ${message}`);
              throw error;
            }
          }
        },
        {
          name: "openai_test_text_small",
          fn: async (runtime) => {
            try {
              const text = await runtime.useModel(ModelType.TEXT_SMALL, {
                prompt: "What is the nature of reality in 10 words?"
              });
              if (text.length === 0) {
                throw new Error("Failed to generate text");
              }
              logger.log({ text }, "generated with test_text_small");
            } catch (error) {
              const message = error instanceof Error ? error.message : String(error);
              logger.error(`Error in test_text_small: ${message}`);
              throw error;
            }
          }
        },
        {
          name: "openai_test_image_generation",
          fn: async (runtime) => {
            logger.log("openai_test_image_generation");
            try {
              const image = await runtime.useModel(ModelType.IMAGE, {
                prompt: "A beautiful sunset over a calm ocean",
                n: 1,
                size: "1024x1024"
              });
              logger.log({ image }, "generated with test_image_generation");
            } catch (error) {
              const message = error instanceof Error ? error.message : String(error);
              logger.error(`Error in test_image_generation: ${message}`);
              throw error;
            }
          }
        },
        {
          name: "image-description",
          fn: async (runtime) => {
            try {
              logger.log("openai_test_image_description");
              try {
                const result = await runtime.useModel(ModelType.IMAGE_DESCRIPTION, "https://upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Vitalik_Buterin_TechCrunch_London_2015_%28cropped%29.jpg/537px-Vitalik_Buterin_TechCrunch_London_2015_%28cropped%29.jpg");
                if (result && typeof result === "object" && "title" in result && "description" in result) {
                  logger.log({ result }, "Image description");
                } else {
                  logger.error("Invalid image description result format:", result);
                }
              } catch (e) {
                const message = e instanceof Error ? e.message : String(e);
                logger.error(`Error in image description test: ${message}`);
              }
            } catch (e) {
              const message = e instanceof Error ? e.message : String(e);
              logger.error(`Error in openai_test_image_description: ${message}`);
            }
          }
        },
        {
          name: "openai_test_transcription",
          fn: async (runtime) => {
            logger.log("openai_test_transcription");
            try {
              const response = await fetch("https://upload.wikimedia.org/wikipedia/en/4/40/Chris_Benoit_Voice_Message.ogg");
              const arrayBuffer = await response.arrayBuffer();
              const transcription = await runtime.useModel(ModelType.TRANSCRIPTION, Buffer.from(new Uint8Array(arrayBuffer)));
              logger.log({ transcription }, "generated with test_transcription");
            } catch (error) {
              const message = error instanceof Error ? error.message : String(error);
              logger.error(`Error in test_transcription: ${message}`);
              throw error;
            }
          }
        },
        {
          name: "openai_test_text_tokenizer_encode",
          fn: async (runtime) => {
            const prompt = "Hello tokenizer encode!";
            const tokens = await runtime.useModel(ModelType.TEXT_TOKENIZER_ENCODE, { prompt });
            if (!Array.isArray(tokens) || tokens.length === 0) {
              throw new Error("Failed to tokenize text: expected non-empty array of tokens");
            }
            logger.log({ tokens }, "Tokenized output");
          }
        },
        {
          name: "openai_test_text_tokenizer_decode",
          fn: async (runtime) => {
            const prompt = "Hello tokenizer decode!";
            const tokens = await runtime.useModel(ModelType.TEXT_TOKENIZER_ENCODE, { prompt });
            const decodedText = await runtime.useModel(ModelType.TEXT_TOKENIZER_DECODE, { tokens });
            if (decodedText !== prompt) {
              throw new Error(`Decoded text does not match original. Expected "${prompt}", got "${decodedText}"`);
            }
            logger.log({ decodedText }, "Decoded text");
          }
        },
        {
          name: "openai_test_text_to_speech",
          fn: async (runtime) => {
            try {
              const response = await fetchTextToSpeech(runtime, {
                text: "Hello, this is a test for text-to-speech."
              });
              if (!response) {
                throw new Error("Failed to generate speech");
              }
              logger.log("Generated speech successfully");
            } catch (error) {
              const message = error instanceof Error ? error.message : String(error);
              logger.error(`Error in openai_test_text_to_speech: ${message}`);
              throw error;
            }
          }
        }
      ]
    }
  ]
};
var src_default = openaiPlugin;
export {
  openaiPlugin,
  src_default as default
};

//# debugId=B1A62305054258BB64756E2164756E21
