import{createOpenAI as x}from"@ai-sdk/openai";import{EventType as b,logger as X,ModelType as F,VECTOR_DIMS as N}from"@elizaos/core";import{generateObject as M,generateText as V,JSONParseError as P}from"ai";import{encodingForModel as U}from"js-tiktoken";function z(Q,G,W){return Q.getSetting(G)??process.env[G]??W}function h(){return typeof globalThis<"u"&&typeof globalThis.document<"u"}function c(Q){return h()&&!!z(Q,"OPENAI_BROWSER_BASE_URL")}function K(Q,G=!1){if(h())return{};let W=G?y(Q):O(Q);return W?{Authorization:`Bearer ${W}`}:{}}function j(Q){let G=z(Q,"OPENAI_BROWSER_BASE_URL"),W=h()&&G?G:z(Q,"OPENAI_BASE_URL","https://api.openai.com/v1");return X.debug(`[OpenAI] Default base URL: ${W}`),W}function T(Q){let G=h()?z(Q,"OPENAI_BROWSER_EMBEDDING_URL")||z(Q,"OPENAI_BROWSER_BASE_URL"):z(Q,"OPENAI_EMBEDDING_URL");if(G)return X.debug(`[OpenAI] Using specific embedding base URL: ${G}`),G;return X.debug("[OpenAI] Falling back to general base URL for embeddings."),j(Q)}function O(Q){return z(Q,"OPENAI_API_KEY")}function y(Q){let G=z(Q,"OPENAI_EMBEDDING_API_KEY");if(G)return X.debug("[OpenAI] Using specific embedding API key (present)"),G;return X.debug("[OpenAI] Falling back to general API key for embeddings."),O(Q)}function A(Q){return z(Q,"OPENAI_SMALL_MODEL")??z(Q,"SMALL_MODEL","gpt-5-nano")}function D(Q){return z(Q,"OPENAI_LARGE_MODEL")??z(Q,"LARGE_MODEL","gpt-5-mini")}function d(Q){return z(Q,"OPENAI_IMAGE_DESCRIPTION_MODEL","gpt-5-nano")??"gpt-5-nano"}function k(Q){let G=z(Q,"OPENAI_EXPERIMENTAL_TELEMETRY","false"),W=String(G).toLowerCase(),Y=W==="true";return X.debug(`[OpenAI] Experimental telemetry in function: "${G}" (type: ${typeof G}, normalized: "${W}", result: ${Y})`),Y}function B(Q){let G=j(Q),W=O(Q)??(c(Q)?"sk-proxy":void 0);return x({apiKey:W??"",baseURL:G})}async function l(Q,G){let W=Q===F.TEXT_SMALL?process.env.OPENAI_SMALL_MODEL??process.env.SMALL_MODEL??"gpt-5-nano":process.env.LARGE_MODEL??"gpt-5-mini";return U(W).encode(G)}async function u(Q,G){let W=Q===F.TEXT_SMALL?process.env.OPENAI_SMALL_MODEL??process.env.SMALL_MODEL??"gpt-5-nano":process.env.OPENAI_LARGE_MODEL??process.env.LARGE_MODEL??"gpt-5-mini";return U(W).decode(G)}async function E(Q,G,W,Y){let C=B(Q),H=Y(Q);X.log(`[OpenAI] Using ${W} model: ${H}`);let _=G.temperature??0;if(!!G.schema)X.info(`Using ${W} without schema validation (schema provided but output=no-schema)`);try{let{object:$,usage:Z}=await M({model:C.languageModel(H),output:"no-schema",prompt:G.prompt,temperature:_,experimental_repairText:L()});if(Z)v(Q,W,G.prompt,Z);return $}catch($){if($ instanceof P){X.error(`[generateObject] Failed to parse JSON: ${$.message}`);let I=await L()({text:$.text,error:$});if(I)try{let w=JSON.parse(I);return X.info("[generateObject] Successfully repaired JSON."),w}catch(w){let q=w instanceof Error?w.message:String(w);throw X.error(`[generateObject] Failed to parse repaired JSON: ${q}`),w}else throw X.error("[generateObject] JSON repair failed."),$}else{let Z=$ instanceof Error?$.message:String($);throw X.error(`[generateObject] Unknown error: ${Z}`),$}}}function L(){return async({text:Q,error:G})=>{try{if(G instanceof P){let W=Q.replace(/```json\n|\n```|```/g,"");return JSON.parse(W),W}return null}catch(W){let Y=W instanceof Error?W.message:String(W);return X.warn(`Failed to repair JSON text: ${Y}`),null}}}function v(Q,G,W,Y){Q.emitEvent(b.MODEL_USED,{provider:"openai",type:G,prompt:W,tokens:{prompt:Y.inputTokens,completion:Y.outputTokens,total:Y.totalTokens}})}async function f(Q,G){let W=z(Q,"OPENAI_TTS_MODEL","gpt-4o-mini-tts"),Y=z(Q,"OPENAI_TTS_VOICE","nova"),C=z(Q,"OPENAI_TTS_INSTRUCTIONS",""),H=j(Q),_=G.model||W,J=G.voice||Y,$=G.instructions??C,Z=G.format||"mp3";try{let I=await fetch(`${H}/audio/speech`,{method:"POST",headers:{...K(Q),"Content-Type":"application/json",...Z==="mp3"?{Accept:"audio/mpeg"}:{}},body:JSON.stringify({model:_,voice:J,input:G.text,format:Z,...$&&{instructions:$}})});if(!I.ok){let w=await I.text();throw Error(`OpenAI TTS error ${I.status}: ${w}`)}return I.body}catch(I){let w=I instanceof Error?I.message:String(I);throw Error(`Failed to fetch speech from OpenAI TTS: ${w}`)}}var p={name:"openai",description:"OpenAI plugin",config:{OPENAI_API_KEY:process.env.OPENAI_API_KEY,OPENAI_BASE_URL:process.env.OPENAI_BASE_URL,OPENAI_SMALL_MODEL:process.env.OPENAI_SMALL_MODEL,OPENAI_LARGE_MODEL:process.env.OPENAI_LARGE_MODEL,SMALL_MODEL:process.env.SMALL_MODEL,LARGE_MODEL:process.env.LARGE_MODEL,OPENAI_EMBEDDING_MODEL:process.env.OPENAI_EMBEDDING_MODEL,OPENAI_EMBEDDING_API_KEY:process.env.OPENAI_EMBEDDING_API_KEY,OPENAI_EMBEDDING_URL:process.env.OPENAI_EMBEDDING_URL,OPENAI_EMBEDDING_DIMENSIONS:process.env.OPENAI_EMBEDDING_DIMENSIONS,OPENAI_IMAGE_DESCRIPTION_MODEL:process.env.OPENAI_IMAGE_DESCRIPTION_MODEL,OPENAI_IMAGE_DESCRIPTION_MAX_TOKENS:process.env.OPENAI_IMAGE_DESCRIPTION_MAX_TOKENS,OPENAI_EXPERIMENTAL_TELEMETRY:process.env.OPENAI_EXPERIMENTAL_TELEMETRY},async init(Q,G){new Promise(async(W)=>{W();try{if(!O(G)&&!h()){X.warn("OPENAI_API_KEY is not set in environment - OpenAI functionality will be limited");return}try{let Y=j(G),C=await fetch(`${Y}/models`,{headers:{...K(G)}});if(!C.ok)X.warn(`OpenAI API key validation failed: ${C.statusText}`),X.warn("OpenAI functionality will be limited until a valid API key is provided");else X.log("OpenAI API key validated successfully")}catch(Y){let C=Y instanceof Error?Y.message:String(Y);X.warn(`Error validating OpenAI API key: ${C}`),X.warn("OpenAI functionality will be limited until a valid API key is provided")}}catch(Y){let C=Y?.errors?.map((H)=>H.message).join(", ")||(Y instanceof Error?Y.message:String(Y));X.warn(`OpenAI plugin configuration issue: ${C} - You need to configure the OPENAI_API_KEY in your environment variables`)}})},models:{[F.TEXT_EMBEDDING]:async(Q,G)=>{let W=z(Q,"OPENAI_EMBEDDING_MODEL","text-embedding-3-small"),Y=Number.parseInt(z(Q,"OPENAI_EMBEDDING_DIMENSIONS","1536")||"1536",10);if(!Object.values(N).includes(Y)){let _=`Invalid embedding dimension: ${Y}. Must be one of: ${Object.values(N).join(", ")}`;throw X.error(_),Error(_)}if(G===null){X.debug("Creating test embedding for initialization");let _=Array(Y).fill(0);return _[0]=0.1,_}let C;if(typeof G==="string")C=G;else if(typeof G==="object"&&G.text)C=G.text;else{X.warn("Invalid input format for embedding");let _=Array(Y).fill(0);return _[0]=0.2,_}if(!C.trim()){X.warn("Empty text for embedding");let _=Array(Y).fill(0);return _[0]=0.3,_}let H=T(Q);try{let _=await fetch(`${H}/embeddings`,{method:"POST",headers:{...K(Q,!0),"Content-Type":"application/json"},body:JSON.stringify({model:W,input:C})});if(!_.ok){X.error(`OpenAI API error: ${_.status} - ${_.statusText}`);let Z=Array(Y).fill(0);return Z[0]=0.4,Z}let J=await _.json();if(!J?.data?.[0]?.embedding){X.error("API returned invalid structure");let Z=Array(Y).fill(0);return Z[0]=0.5,Z}let $=J.data[0].embedding;if(J.usage){let Z={inputTokens:J.usage.prompt_tokens,outputTokens:0,totalTokens:J.usage.total_tokens};v(Q,F.TEXT_EMBEDDING,C,Z)}return X.log(`Got valid embedding with length ${$.length}`),$}catch(_){let J=_ instanceof Error?_.message:String(_);X.error(`Error generating embedding: ${J}`);let $=Array(Y).fill(0);return $[0]=0.6,$}},[F.TEXT_TOKENIZER_ENCODE]:async(Q,{prompt:G,modelType:W=F.TEXT_LARGE})=>{return await l(W??F.TEXT_LARGE,G)},[F.TEXT_TOKENIZER_DECODE]:async(Q,{tokens:G,modelType:W=F.TEXT_LARGE})=>{return await u(W??F.TEXT_LARGE,G)},[F.TEXT_SMALL]:async(Q,{prompt:G,stopSequences:W=[],maxTokens:Y=8192,temperature:C=0.7,frequencyPenalty:H=0.7,presencePenalty:_=0.7})=>{let J=B(Q),$=A(Q),Z=k(Q);X.log(`[OpenAI] Using TEXT_SMALL model: ${$}`),X.log(G);let{text:I,usage:w}=await V({model:J.languageModel($),prompt:G,system:Q.character.system??void 0,temperature:C,maxOutputTokens:Y,frequencyPenalty:H,presencePenalty:_,stopSequences:W,experimental_telemetry:{isEnabled:Z}});if(w)v(Q,F.TEXT_SMALL,G,w);return I},[F.TEXT_LARGE]:async(Q,{prompt:G,stopSequences:W=[],maxTokens:Y=8192,temperature:C=0.7,frequencyPenalty:H=0.7,presencePenalty:_=0.7})=>{let J=B(Q),$=D(Q),Z=k(Q);X.log(`[OpenAI] Using TEXT_LARGE model: ${$}`),X.log(G);let{text:I,usage:w}=await V({model:J.languageModel($),prompt:G,system:Q.character.system??void 0,temperature:C,maxOutputTokens:Y,frequencyPenalty:H,presencePenalty:_,stopSequences:W,experimental_telemetry:{isEnabled:Z}});if(w)v(Q,F.TEXT_LARGE,G,w);return I},[F.IMAGE]:async(Q,G)=>{let W=G.n||1,Y=G.size||"1024x1024",C=G.prompt,H="gpt-image-1";X.log("[OpenAI] Using IMAGE model: gpt-image-1");let _=j(Q);try{let J=await fetch(`${_}/images/generations`,{method:"POST",headers:{...K(Q),"Content-Type":"application/json"},body:JSON.stringify({model:"gpt-image-1",prompt:C,n:W,size:Y})});if(!J.ok)throw Error(`Failed to generate image: ${J.statusText}`);return(await J.json()).data}catch(J){let $=J instanceof Error?J.message:String(J);throw J}},[F.IMAGE_DESCRIPTION]:async(Q,G)=>{let W,Y,C=d(Q);X.log(`[OpenAI] Using IMAGE_DESCRIPTION model: ${C}`);let H=Number.parseInt(z(Q,"OPENAI_IMAGE_DESCRIPTION_MAX_TOKENS","8192")||"8192",10);if(typeof G==="string")W=G,Y="Please analyze this image and provide a title and detailed description.";else W=G.imageUrl,Y=G.prompt||"Please analyze this image and provide a title and detailed description.";let _=[{role:"user",content:[{type:"text",text:Y},{type:"image_url",image_url:{url:W}}]}],J=j(Q);try{let $={model:C,messages:_,max_tokens:H},Z=await fetch(`${J}/chat/completions`,{method:"POST",headers:{"Content-Type":"application/json",...K(Q)},body:JSON.stringify($)});if(!Z.ok)throw Error(`OpenAI API error: ${Z.status}`);let w=await Z.json(),q=w.choices?.[0]?.message?.content;if(w.usage)v(Q,F.IMAGE_DESCRIPTION,typeof G==="string"?G:G.prompt||"",{inputTokens:w.usage.prompt_tokens,outputTokens:w.usage.completion_tokens,totalTokens:w.usage.total_tokens});if(!q)return{title:"Failed to analyze image",description:"No response from API"};if(typeof G==="object"&&G.prompt&&G.prompt!=="Please analyze this image and provide a title and detailed description.")return q;let R=q.match(/title[:\s]+(.+?)(?:\n|$)/i)?.[1]?.trim()||"Image Analysis",S=q.replace(/title[:\s]+(.+?)(?:\n|$)/i,"").trim();return{title:R,description:S}}catch($){let Z=$ instanceof Error?$.message:String($);return X.error(`Error analyzing image: ${Z}`),{title:"Failed to analyze image",description:`Error: ${Z}`}}},[F.TRANSCRIPTION]:async(Q,G)=>{let W=z(Q,"OPENAI_TRANSCRIPTION_MODEL","gpt-4o-mini-transcribe");X.log(`[OpenAI] Using TRANSCRIPTION model: ${W}`);let Y=j(Q),C,H=null;if(G instanceof Blob||G instanceof File)C=G;else if(typeof G==="object"&&G!==null&&G.audio!=null){let Z=G;if(!(Z.audio instanceof Blob)&&!(Z.audio instanceof File))throw Error("TRANSCRIPTION param 'audio' must be a Blob/File. Wrap buffers as: new Blob([buffer], { type: 'audio/mpeg' })");if(C=Z.audio,H=Z,typeof Z.model==="string"&&Z.model)W=Z.model}else throw Error("TRANSCRIPTION expects a Blob/File or an object { audio: Blob/File, language?, response_format?, timestampGranularities?, prompt?, temperature?, model? }");let _=C.type||"audio/webm",J=C.name||(_.includes("mp3")||_.includes("mpeg")?"recording.mp3":_.includes("ogg")?"recording.ogg":_.includes("wav")?"recording.wav":_.includes("webm")?"recording.webm":"recording.bin"),$=new FormData;if($.append("file",C,J),$.append("model",String(W)),H){if(typeof H.language==="string")$.append("language",String(H.language));if(typeof H.response_format==="string")$.append("response_format",String(H.response_format));if(typeof H.prompt==="string")$.append("prompt",String(H.prompt));if(typeof H.temperature==="number")$.append("temperature",String(H.temperature));if(Array.isArray(H.timestampGranularities))for(let Z of H.timestampGranularities)$.append("timestamp_granularities[]",String(Z))}try{let Z=await fetch(`${Y}/audio/transcriptions`,{method:"POST",headers:{...K(Q)},body:$});if(!Z.ok)throw Error(`Failed to transcribe audio: ${Z.status} ${Z.statusText}`);return(await Z.json()).text||""}catch(Z){let I=Z instanceof Error?Z.message:String(Z);throw X.error(`TRANSCRIPTION error: ${I}`),Z}},[F.TEXT_TO_SPEECH]:async(Q,G)=>{let W=typeof G==="string"?{text:G}:G,Y=W.model||z(Q,"OPENAI_TTS_MODEL","gpt-4o-mini-tts");X.log(`[OpenAI] Using TEXT_TO_SPEECH model: ${Y}`);try{return await f(Q,W)}catch(C){let H=C instanceof Error?C.message:String(C);throw X.error(`Error in TEXT_TO_SPEECH: ${H}`),C}},[F.OBJECT_SMALL]:async(Q,G)=>{return E(Q,G,F.OBJECT_SMALL,A)},[F.OBJECT_LARGE]:async(Q,G)=>{return E(Q,G,F.OBJECT_LARGE,D)}},tests:[{name:"openai_plugin_tests",tests:[{name:"openai_test_url_and_api_key_validation",fn:async(Q)=>{let G=j(Q),W=await fetch(`${G}/models`,{headers:{Authorization:`Bearer ${O(Q)}`}}),Y=await W.json();if(X.log({data:Y?.data?.length??"N/A"},"Models Available"),!W.ok)throw Error(`Failed to validate OpenAI API key: ${W.statusText}`)}},{name:"openai_test_text_embedding",fn:async(Q)=>{try{let G=await Q.useModel(F.TEXT_EMBEDDING,{text:"Hello, world!"});X.log({embedding:G},"embedding")}catch(G){let W=G instanceof Error?G.message:String(G);throw X.error(`Error in test_text_embedding: ${W}`),G}}},{name:"openai_test_text_large",fn:async(Q)=>{try{let G=await Q.useModel(F.TEXT_LARGE,{prompt:"What is the nature of reality in 10 words?"});if(G.length===0)throw Error("Failed to generate text");X.log({text:G},"generated with test_text_large")}catch(G){let W=G instanceof Error?G.message:String(G);throw X.error(`Error in test_text_large: ${W}`),G}}},{name:"openai_test_text_small",fn:async(Q)=>{try{let G=await Q.useModel(F.TEXT_SMALL,{prompt:"What is the nature of reality in 10 words?"});if(G.length===0)throw Error("Failed to generate text");X.log({text:G},"generated with test_text_small")}catch(G){let W=G instanceof Error?G.message:String(G);throw X.error(`Error in test_text_small: ${W}`),G}}},{name:"openai_test_image_generation",fn:async(Q)=>{X.log("openai_test_image_generation");try{let G=await Q.useModel(F.IMAGE,{prompt:"A beautiful sunset over a calm ocean",n:1,size:"1024x1024"});X.log({image:G},"generated with test_image_generation")}catch(G){let W=G instanceof Error?G.message:String(G);throw X.error(`Error in test_image_generation: ${W}`),G}}},{name:"image-description",fn:async(Q)=>{try{X.log("openai_test_image_description");try{let G=await Q.useModel(F.IMAGE_DESCRIPTION,"https://upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Vitalik_Buterin_TechCrunch_London_2015_%28cropped%29.jpg/537px-Vitalik_Buterin_TechCrunch_London_2015_%28cropped%29.jpg");if(G&&typeof G==="object"&&"title"in G&&"description"in G)X.log({result:G},"Image description");else X.error("Invalid image description result format:",G)}catch(G){let W=G instanceof Error?G.message:String(G);X.error(`Error in image description test: ${W}`)}}catch(G){let W=G instanceof Error?G.message:String(G);X.error(`Error in openai_test_image_description: ${W}`)}}},{name:"openai_test_transcription",fn:async(Q)=>{X.log("openai_test_transcription");try{let W=await(await fetch("https://upload.wikimedia.org/wikipedia/en/4/40/Chris_Benoit_Voice_Message.ogg")).arrayBuffer(),Y=await Q.useModel(F.TRANSCRIPTION,Buffer.from(new Uint8Array(W)));X.log({transcription:Y},"generated with test_transcription")}catch(G){let W=G instanceof Error?G.message:String(G);throw X.error(`Error in test_transcription: ${W}`),G}}},{name:"openai_test_text_tokenizer_encode",fn:async(Q)=>{let W=await Q.useModel(F.TEXT_TOKENIZER_ENCODE,{prompt:"Hello tokenizer encode!"});if(!Array.isArray(W)||W.length===0)throw Error("Failed to tokenize text: expected non-empty array of tokens");X.log({tokens:W},"Tokenized output")}},{name:"openai_test_text_tokenizer_decode",fn:async(Q)=>{let W=await Q.useModel(F.TEXT_TOKENIZER_ENCODE,{prompt:"Hello tokenizer decode!"}),Y=await Q.useModel(F.TEXT_TOKENIZER_DECODE,{tokens:W});if(Y!=="Hello tokenizer decode!")throw Error(`Decoded text does not match original. Expected "Hello tokenizer decode!", got "${Y}"`);X.log({decodedText:Y},"Decoded text")}},{name:"openai_test_text_to_speech",fn:async(Q)=>{try{if(!await f(Q,{text:"Hello, this is a test for text-to-speech."}))throw Error("Failed to generate speech");X.log("Generated speech successfully")}catch(G){let W=G instanceof Error?G.message:String(G);throw X.error(`Error in openai_test_text_to_speech: ${W}`),G}}}]}]},g=p;export{p as openaiPlugin,g as default};

//# debugId=89F51A79E528892264756E2164756E21
